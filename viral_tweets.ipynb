{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Off-Platform Project: Viral Tweets\r\n",
    "\r\n",
    "* The total number of tweets in the dataset.\r\n",
    "* The columns, or features, of the dataset.\r\n",
    "* The text of the first tweet in the dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "all_tweets = pd.read_json(\"random_tweets.json\", lines=True)\r\n",
    "\r\n",
    "print(len(all_tweets))\r\n",
    "print(all_tweets.columns)\r\n",
    "print(all_tweets.loc[0]['text'])\r\n",
    "print(all_tweets.loc[0]['user']['location'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "11099\n",
      "Index(['contributors', 'coordinates', 'created_at', 'entities',\n",
      "       'extended_entities', 'favorite_count', 'favorited', 'geo', 'id',\n",
      "       'id_str', 'in_reply_to_screen_name', 'in_reply_to_status_id',\n",
      "       'in_reply_to_status_id_str', 'in_reply_to_user_id',\n",
      "       'in_reply_to_user_id_str', 'is_quote_status', 'lang', 'metadata',\n",
      "       'place', 'possibly_sensitive', 'quoted_status', 'quoted_status_id',\n",
      "       'quoted_status_id_str', 'retweet_count', 'retweeted',\n",
      "       'retweeted_status', 'source', 'text', 'truncated', 'user',\n",
      "       'withheld_in_countries'],\n",
      "      dtype='object')\n",
      "RT @KWWLStormTrack7: We are more than a month into summer but the days are getting shorter. The sunrise is about 25 minutes later on July 3â€¦\n",
      "Waterloo, Iowa\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining Viral Tweets\r\n",
    "\r\n",
    "K-Nearest Neighbor classifier "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "median_retweets = all_tweets['retweet_count'].median()\r\n",
    "print(median_retweets)\r\n",
    "all_tweets['is_viral'] = np.where(all_tweets['retweet_count'] >= median_retweets, 1, 0)\r\n",
    "print(all_tweets['is_viral'].value_counts())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "13.0\n",
      "1    5591\n",
      "0    5508\n",
      "Name: is_viral, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Making Features\r\n",
    "\r\n",
    "* The number of hashtags in the tweet. \r\n",
    "* The number of links in the tweet. \r\n",
    "* The number of words in the tweet. \r\n",
    "* The average length of the words in the tweet."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "all_tweets['tweet_length'] = all_tweets.apply(lambda tweet: len(tweet['text']), axis=1)\r\n",
    "all_tweets['followers_count'] = all_tweets.apply(lambda tweet: tweet['user']['followers_count'], axis=1)\r\n",
    "all_tweets['friends_count'] = all_tweets.apply(lambda tweet: tweet['user']['friends_count'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Normalizing The Data\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from sklearn.preprocessing import scale\r\n",
    "\r\n",
    "labels = all_tweets['is_viral']\r\n",
    "data = all_tweets[['tweet_length','followers_count','friends_count']]\r\n",
    "scaled_data = scale(data, axis=0)\r\n",
    "\r\n",
    "print(scaled_data[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0.6164054  -0.02878298 -0.14483305]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating the Training Set and Test Set\r\n",
    "\r\n",
    "\r\n",
    "1. The training data\r\n",
    "2. The testing data\r\n",
    "3. The training labels\r\n",
    "4. The testing labels\r\n",
    "\r\n",
    "storing the results in variables named `train_data`, `test_data`, `train_labels`, and `test_labels`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(scaled_data, labels, test_size = 0.2, random_state = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using the Classifier\r\n",
    "\r\n",
    "K-Nearest Neighbor classifier\r\n",
    "`k = 5`\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5)\r\n",
    "classifier.fit(train_data, train_labels)\r\n",
    "print(classifier.score(test_data, test_labels))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5905405405405405\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Choosing K\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "scores = []\r\n",
    "for k in range(1, 200):\r\n",
    "    classifier = KNeighborsClassifier(n_neighbors = k)\r\n",
    "    classifier.fit(train_data, train_labels)\r\n",
    "    scores.append(classifier.score(test_data, test_labels))\r\n",
    "    \r\n",
    "plt.plot(range(1,200), scores)\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}